{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ectP4Po5hUc8"
      },
      "source": [
        "# Hyperparameter Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70QJPdYshUc9"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PYTKZPMmhUc-"
      },
      "outputs": [],
      "source": [
        "# Import packages \n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm, trange \n",
        "import glob\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnoQ_H6WhUc_"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d_dsOlXghUdA"
      },
      "outputs": [],
      "source": [
        "# double convolutional layer which is executed in every step of the u-net \n",
        "# conv layer takes as input number of input channels -> in_channels and outputs vice versa\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    # forward pass in the conv layer \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# design complete u-net shape \n",
        "# model takes as default 3 input channels and 6 output channels\n",
        "class UNET(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_channels=3, out_channels=6, features=[64, 128, 256, 512],  # features -> num of input nodes at every stage in the model \n",
        "    ):\n",
        "        super(UNET, self).__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET\n",
        "        for feature in reversed(features):  # reverse the features i.o. to move upwards in the model \n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2,\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "        \n",
        "        # lowest stage in u-net \n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        # final conv layer: takes in 64 channels and outputs 1 channel by default \n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    # forward pass of the u-net model between stages \n",
        "    def forward(self, x):\n",
        "        skip_connections = []  # red arrows in the model representation \n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)  # one DoubleConv run-through \n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3nHg60_hUdB"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_KLNBKZhUdC",
        "outputId": "2d11540a-9801-4153-ee7a-def100615eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Establish connection with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path variable\n",
        "path = \"/content/drive/MyDrive/DS-Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dm1UcYCehUdD"
      },
      "outputs": [],
      "source": [
        "# Create lists with paths to all image and label data \n",
        "imgs = glob.glob(path+'data/model_training/2_Ortho_RGB/sliced/*tif')\n",
        "labels = glob.glob(path+\"data/model_training/Labels_all/sliced/*tif\")\n",
        "\n",
        "# Create dictionary -> {key: 'link/to/image_or_label'}\n",
        "labels_dict = {label.split(\"/\")[-1].split(\".\")[0].rsplit('_', 1)[0] : label for label in labels}\n",
        "imgs_dict = {img.split(\"/\")[-1].split(\".\")[0].rsplit('_', 1)[0] : img for img in imgs}\n",
        "\n",
        "# Create list with all keys \n",
        "keys = sorted(list(set(imgs_dict)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni2ujo18hUdD"
      },
      "source": [
        "## Custom Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IB2o841uhUdD"
      },
      "outputs": [],
      "source": [
        "class PotsdamDataset(Dataset):\n",
        "    def __init__(self, imgs_dict, labels_dict, keys, transform=None):\n",
        "        self.img_dir = imgs_dict\n",
        "        self.mask_dir = labels_dict\n",
        "        self.keys = keys\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.RGB_classes = {\n",
        "            'imprevious' : [255, 255, 225],\n",
        "            'building' : [0,  0, 255],\n",
        "            'low_vegetation' : [0, 255, 255],\n",
        "            'tree' : [0,  255,  0], \n",
        "            'car' : [ 255, 255, 0],\n",
        "            'background' : [255, 0, 0]\n",
        "            }  # in RGB\n",
        "        \n",
        "        self.bin_classes = ['imprevious', 'building', 'low_vegetation', 'tree', 'car', 'background']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_dir[self.keys[idx]]\n",
        "        mask_path = self.mask_dir[self.keys[idx]]\n",
        "        \n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"RGB\"))\n",
        "        \n",
        "        cls_mask = np.zeros(mask.shape) # dim: (6000, 6000, 3)\n",
        "        \n",
        "        cls_mask[(mask == self.RGB_classes['imprevious']).all(-1)] = self.bin_classes.index('imprevious')\n",
        "        cls_mask[(mask == self.RGB_classes['building']).all(-1)] = self.bin_classes.index('building')\n",
        "        cls_mask[(mask == self.RGB_classes['low_vegetation']).all(-1)] = self.bin_classes.index('low_vegetation')\n",
        "        cls_mask[(mask == self.RGB_classes['tree']).all(-1)] = self.bin_classes.index('tree')\n",
        "        cls_mask[(mask == self.RGB_classes['car']).all(-1)] = self.bin_classes.index('car')\n",
        "        cls_mask[(mask == self.RGB_classes['background']).all(-1)] = self.bin_classes.index('background')\n",
        "        cls_mask = cls_mask[:,:,0] # omit last dimension (, , 3) -> RGB  \n",
        "\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=cls_mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VibTkaHphUdE"
      },
      "source": [
        "## Util Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYj6W8q0hUdE"
      },
      "source": [
        "### Train-/Validation-Split "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CAS_HMYzhUdE"
      },
      "outputs": [],
      "source": [
        "dataset = PotsdamDataset(imgs_dict, labels_dict, keys)\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ecai5j_-hUdE"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hMILpEt6hUdF"
      },
      "outputs": [],
      "source": [
        "def get_loaders(\n",
        "    imgs_dict,\n",
        "    labels_dict,\n",
        "    keys,\n",
        "    batch_size,\n",
        "    train_transform,\n",
        "    val_transform,\n",
        "    num_workers = 2,\n",
        "    pin_memory = True,\n",
        "):\n",
        "    \n",
        "    train_data = PotsdamDataset(\n",
        "        imgs_dict = imgs_dict,\n",
        "        labels_dict = labels_dict,\n",
        "        keys = keys, \n",
        "        transform = train_transform,\n",
        "    )\n",
        "    \n",
        "    valid_data = PotsdamDataset(\n",
        "        imgs_dict = imgs_dict,\n",
        "        labels_dict = labels_dict,\n",
        "        keys = keys, \n",
        "        transform = val_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size = batch_size,\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = pin_memory,\n",
        "        sampler = train_sampler,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        valid_data,\n",
        "        batch_size = batch_size,\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = pin_memory,\n",
        "        sampler = valid_sampler\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF3pDRmJhUdF"
      },
      "source": [
        "### Transform Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sYJ3D_JZhUdF"
      },
      "outputs": [],
      "source": [
        "def build_transforms(image_heigt, image_width): \n",
        "    \n",
        "    train_transform = A.Compose([\n",
        "        A.Resize(height=image_heigt, width=image_width),\n",
        "        A.Flip(p=0.5),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), \n",
        "                    std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "        ],)\n",
        "\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(height=image_heigt, width=image_width),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), \n",
        "                    std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "        ],)\n",
        "    \n",
        "    return train_transform, val_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIXJdWHwhUdF"
      },
      "source": [
        "### Accuracy Function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qwwlvw0KhUdF"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(y_pred, y):\n",
        "\n",
        "    preds = torch.argmax(y_pred, axis=1).cpu()\n",
        "    num_correct = (preds == y).sum().item()\n",
        "    num_pixels = torch.numel(preds)\n",
        "\n",
        "    return num_correct/num_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkXHWHMmhUdG"
      },
      "source": [
        "### Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            # compute probabilities\n",
        "            probs = torch.nn.Softmax(model(x))\n",
        "            # get predictions by choosing highest probability \n",
        "            preds = torch.argmax(probs.dim, axis=1).cpu()\n",
        "            num_correct += (preds == y).sum().item()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            \n",
        "            #print(num_correct, num_pixels)\n",
        "\n",
        "    print(\n",
        "        f\"Got {num_correct}/{num_pixels} pixels correct with acc {num_correct/num_pixels*100:.2f}\"\n",
        "    )\n",
        "\n",
        "    return num_correct/num_pixels"
      ],
      "metadata": {
        "id": "u5GIsvx0lCZY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hO5UM9Y4hUdG"
      },
      "outputs": [],
      "source": [
        "def evaluate_fn(model, loader, criterion, device):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "  loop = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for x, y in loop:\n",
        "\n",
        "      x = x.to(device)\n",
        "      y = y.type(torch.LongTensor).to(device)\n",
        "\n",
        "      y_pred = model(x)\n",
        "\n",
        "      loss = criterion(y_pred, y)\n",
        "\n",
        "      acc = compute_accuracy(y_pred, y.cpu())\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc\n",
        "\n",
        "  return epoch_loss / len(loader), epoch_acc / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jaKxh_VZhUdG"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  \n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0inlfWkLhUdG"
      },
      "source": [
        "## Configure Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_07hBpwhUdG",
        "outputId": "2acad673-b0e9-4b62-ca04-b3315b16e1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.13.9)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.13.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.30)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mameisen-elefant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Setup wandb \n",
        "!pip install wandb --upgrade\n",
        "import pprint\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MIyZdRA3hUdG"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'validation_accuracy',\n",
        "    'goal': 'maximize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6KwoJPhUdG",
        "outputId": "ca886ed7-f1f4-4297-81a3-8c50396c552b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'maximize', 'name': 'validation_accuracy'},\n",
            " 'parameters': {'batch_size': {'values': [4, 8]},\n",
            "                'epochs': {'values': [2, 4, 8]},\n",
            "                'learning_rate': {'distribution': 'uniform',\n",
            "                                  'max': 0.005,\n",
            "                                  'min': 1e-05}}}\n"
          ]
        }
      ],
      "source": [
        "parameters_dict = {\n",
        "    'batch_size': {\n",
        "        'values': [4, 8]\n",
        "        },\n",
        "    'learning_rate': {\n",
        "        # a flat distribution\n",
        "        'distribution': 'uniform',\n",
        "        'min': 1e-5,\n",
        "        'max': 5e-3\n",
        "        },\n",
        "    'epochs': {'values': [2, 4, 8]\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6EUMBR4hUdH",
        "outputId": "6dab40d2-8fa6-458f-9906-5957833caaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: fftbm0sl\n",
            "Sweep URL: https://wandb.ai/ameisen-elefant/ds_project/sweeps/fftbm0sl\n"
          ]
        }
      ],
      "source": [
        "# initialize sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"ds_project\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJXXpWIDhUdH"
      },
      "source": [
        "## HP Search "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bwEHqEvLhUdH"
      },
      "outputs": [],
      "source": [
        "#def train_fn(loader, model, optimizer, criterion, scaler, device):\n",
        "def train_fn(loader, model, optimizer, criterion, device):\n",
        "  \n",
        "  model.train()\n",
        "  loop = tqdm(loader, desc=\"Training\")\n",
        "  \n",
        "  for batch_idx, (data, targets) in enumerate(loop):\n",
        "    data = data.to(device)\n",
        "    targets = targets.type(torch.LongTensor).to(device)\n",
        "\n",
        "    # forward\n",
        "    # with torch.cuda.amp.autocast():\n",
        "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "      predictions = model(data)\n",
        "      loss = criterion(predictions, targets)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # backward + scaler\n",
        "    # optimizer.zero_grad()\n",
        "    # scaler.scale(loss).backward()\n",
        "    # scaler.step(optimizer)\n",
        "    # scaler.update()\n",
        "\n",
        "    # update tqdm loop\n",
        "    loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5bF0XXmShUdH"
      },
      "outputs": [],
      "source": [
        "IMAGE_HEIGHT = 1000  # 2000 originally\n",
        "IMAGE_WIDTH = 1000  # 2000 originally\n",
        "\n",
        "IMGS_DICT = imgs_dict\n",
        "LABELS_DICT = labels_dict\n",
        "KEYS = keys\n",
        "\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kmf52z0_hUdH"
      },
      "outputs": [],
      "source": [
        "def main(config=None):\n",
        "    \n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "        \n",
        "        train_transforms, val_transforms = build_transforms(\n",
        "            image_heigt=IMAGE_HEIGHT,\n",
        "            image_width=IMAGE_WIDTH\n",
        "        )\n",
        "        \n",
        "        train_loader, validation_loader = get_loaders(\n",
        "            imgs_dict=IMGS_DICT,\n",
        "            labels_dict=LABELS_DICT,\n",
        "            keys=KEYS,\n",
        "            batch_size=config.batch_size,\n",
        "            train_transform=train_transforms,\n",
        "            val_transform=val_transforms,\n",
        "            num_workers = NUM_WORKERS,\n",
        "            pin_memory = PIN_MEMORY)\n",
        "        \n",
        "        # specify loss function \n",
        "        CRITERION = nn.CrossEntropyLoss().to(device=DEVICE)\n",
        "        \n",
        "        # initialize model and optimizer\n",
        "        MODEL = UNET(in_channels=3, out_channels=6).to(device=DEVICE)\n",
        "        OPTIMIZER = optim.Adam(MODEL.parameters(), lr=config.learning_rate)\n",
        "        \n",
        "        # SCALER = torch.cuda.amp.GradScaler()\n",
        "        \n",
        "        for epoch in range(config.epochs):\n",
        "          print(f\"Start epoch: {epoch+1}\")\n",
        "          \n",
        "          train_fn(\n",
        "              loader=train_loader, \n",
        "              model=MODEL, \n",
        "              optimizer=OPTIMIZER, \n",
        "              criterion=CRITERION, \n",
        "              #scaler=SCALER,\n",
        "              device=DEVICE)\n",
        "          \n",
        "          # check accuracy\n",
        "          validation_accuracy = check_accuracy(validation_loader, MODEL, device=DEVICE)\n",
        "        \n",
        "          print(f\"End epoch: {epoch+1} \\n\")\n",
        "        \n",
        "          wandb.log({\"epoch\": epoch,\n",
        "                     \"validation_accuracy\": validation_accuracy})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%script\n",
        "def main(config=None):\n",
        "    \n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "        \n",
        "        train_transforms, val_transforms = build_transforms(\n",
        "            image_heigt=IMAGE_HEIGHT,\n",
        "            image_width=IMAGE_WIDTH\n",
        "        )\n",
        "        \n",
        "        train_loader, validation_loader = get_loaders(\n",
        "            imgs_dict=IMGS_DICT,\n",
        "            labels_dict=LABELS_DICT,\n",
        "            keys=KEYS,\n",
        "            batch_size=config.batch_size,\n",
        "            train_transform=train_transforms,\n",
        "            val_transform=val_transforms,\n",
        "            num_workers = NUM_WORKERS,\n",
        "            pin_memory = PIN_MEMORY)\n",
        "        \n",
        "        # specify loss function \n",
        "        CRITERION = nn.CrossEntropyLoss().to(device=DEVICE)\n",
        "        \n",
        "        # initialize model and optimizer\n",
        "        MODEL = UNET(in_channels=3, out_channels=6).to(device=DEVICE)\n",
        "        OPTIMIZER = optim.Adam(MODEL.parameters(), lr=config.learning_rate)\n",
        "        \n",
        "        SCALER = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        print(f\"Start epoch: {epoch+1}\")\n",
        "        \n",
        "        train_fn(\n",
        "            loader=train_loader, \n",
        "            model=MODEL, \n",
        "            optimizer=OPTIMIZER, \n",
        "            criterion=CRITERION, \n",
        "            scaler=SCALER,\n",
        "            device=DEVICE)\n",
        "        \n",
        "        # check accuracy\n",
        "        validation_accuracy = check_accuracy(validation_loader, MODEL, device=DEVICE)\n",
        "        \n",
        "        print(f\"End epoch: {epoch+1} \\n\")\n",
        "        \n",
        "        \n",
        "    for epoch in trange(config.epochs, desc=\"Epochs\"):\n",
        "\n",
        "        start_time = time.monotonic()\n",
        "        \n",
        "        train_fn(\n",
        "            loader=train_loader, \n",
        "            model=MODEL, \n",
        "            optimizer=OPTIMIZER, \n",
        "            criterion=CRITERION, \n",
        "            scaler=SCALER,\n",
        "            device=DEVICE)\n",
        "        \n",
        "        training_loss, training_accuracy = evaluate_fn(\n",
        "            model=MODEL, \n",
        "            loader=train_loader, \n",
        "            criterion=CRITERION, \n",
        "            device=DEVICE)\n",
        "        \n",
        "        validation_loss, validation_accuracy = evaluate_fn(\n",
        "            model=MODEL, \n",
        "            loader=validation_loader, \n",
        "            criterion=CRITERION, \n",
        "            device=DEVICE)\n",
        "                \n",
        "        end_time = time.monotonic()\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\t Train Loss: {training_loss:.3f} | Train Acc: {training_accuracy*100:.2f}%')\n",
        "        print(f'\\t Val. Loss: {validation_loss:.3f} |  Val. Acc: {validation_accuracy*100:.2f}%')\n",
        "        \n",
        "        wandb.log({\"epoch\": epoch, \n",
        "                   \"validation_accuracy\": validation_accuracy})"
      ],
      "metadata": {
        "id": "1K9pDsgiAyui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "CiDnyi3vhUdI",
        "outputId": "7a731bef-d608-43e6-912f-f16fed8face7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5udelqz8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0032549387409015647\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230116_162927-5udelqz8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ameisen-elefant/ds_project/runs/5udelqz8\" target=\"_blank\">noble-sweep-1</a></strong> to <a href=\"https://wandb.ai/ameisen-elefant/ds_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/ameisen-elefant/ds_project/sweeps/fftbm0sl\" target=\"_blank\">https://wandb.ai/ameisen-elefant/ds_project/sweeps/fftbm0sl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/ameisen-elefant/ds_project\" target=\"_blank\">https://wandb.ai/ameisen-elefant/ds_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href=\"https://wandb.ai/ameisen-elefant/ds_project/sweeps/fftbm0sl\" target=\"_blank\">https://wandb.ai/ameisen-elefant/ds_project/sweeps/fftbm0sl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/ameisen-elefant/ds_project/runs/5udelqz8\" target=\"_blank\">https://wandb.ai/ameisen-elefant/ds_project/runs/5udelqz8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  63%|██████▎   | 22/35 [01:22<00:41,  3.18s/it, loss=1.71]"
          ]
        }
      ],
      "source": [
        "wandb.agent(sweep_id, main, count=10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data_science",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eb7f5e66918d02d82412820c0a4aa3505fa06a6cc37c5a10c65e43bd94ac1a13"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "70QJPdYshUc9",
        "WnoQ_H6WhUc_",
        "Z3nHg60_hUdB",
        "Ni2ujo18hUdD",
        "dYj6W8q0hUdE",
        "Ecai5j_-hUdE",
        "OF3pDRmJhUdF",
        "JIXJdWHwhUdF",
        "rkXHWHMmhUdG",
        "0inlfWkLhUdG"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}